---
layout:     post
title:      "ビッグデータ分析のシステムと開発がしっかりわかる教科書"
date:       2024-05-18 00:00:00 +0900
categories: it memo
---

![thumbnail](/assets/2024-05-18-big-data-bunnseki-no-system-to-kaihatu-ga-shikkari-wakaru-kyoukasyo/thumbnail.png)

※本ブログの目的と内容[^1]、著作者の方へ[^2]

[^1]: 本ブログは「本を読み、理解した内容の備忘録（自分用）」を目的としている。重要なアイディアを昇華させ、自分の言葉でまとめるように努めている

[^2]: 内容に不快を感じ、ブログの取り下げを希望される著作者の方は、個別にご連絡いただけると幸いに思う

## ビッグデータ分析の全体像

##### システムの全体像

![thumbnail](/assets/2024-05-18-big-data-bunnseki-no-system-to-kaihatu-ga-shikkari-wakaru-kyoukasyo/birds‐eye-view.png)

- 事業システム
  - 高い可用性が求められているいわゆるミッションクリティカルなシステム
- 分析システム
  - 高い可用性は求められないが、分析をスピーディーに試せる高い開発生産性が求められる

### 関係者と役割

- 事業組織 ... 利益を上げている組織
- 分析組織 ... ビッグデータ分析システムを担当する組織

| 人                            | 役割                                                                                      |
|:-----------------------------|:----------------------------------------------------------------------------------------|
| 事業システム担当<br />*事業のシステムに詳しい人  | 事業システムでデータを生成する。                                                                        |
| エンジニアリング<br />*分析システムを支える人 | 分析システム全体の設計・開発・運用をする。<br />メタデータ管理も行う。                                                  |
| サイエンス<br />*分析技術に詳しい人      | データから知見を取り出す方法を実装し、日々改善する。<br />特徴を数値化し、機械学習で類似度を計算したりする。<br />一度開発したモデルが陳腐化していないか監視する。 |
| データビジネス<br />*分析データに詳しい人   | データ分析により企業の利益を上げる。<br />事業担当者が決めた目標（事業の急所として設定されたKPI）を<br />達成するシステム・分析要件への落とし込みを行う。    |
| データ利用者<br />*事業に詳しい人         | SQLでデータを分析して意思決定する。                                                                 |
| データ閲覧者<br />*事業に詳しい人         | 可視化されたデータを見て意思決定する。                                                                 |

#### エンジニアリングの希少価値
エンジニアリング力がないと、**データ分析による継続的な利益向上を維持できない**。

##### 本番システム化に必須な存在
本番システム化は一回限りの実証実験とは異なり、考慮すべき点が大きく変わる。

- 継続的なデータの収集法
- 分析精度の監視
- 分析結果を利益に結びるける箇所の自動化
- 処理が業務時間内に間に合うか
- ソースコード・リリースの管理

##### 希少性
**最初からビッグデータエンジニアリングをできる人はほとんどいない**。
Webシステムや基幹業務システムでインフラ構築・運用経験のある人を採用し、経験を積んでもらうことが現実的な解。

### 活用段階
活用段階の低い企業が、多額の投資でデータアプリケーションをいきなり作ることは現実的ではない。
**スモールスタートでシステムを作り、成果を積み上げて徐々に進化させていく**。

| 段階 | 名前          | 企業の状態                                                                     |
|:---|:------------|:--------------------------------------------------------------------------|
| 1  | アドホック分析     | データをSQLで不定期に分析し、意思決定を行う                                                   |
| 2  | データ可視化      | ダッシュボードでデータを可視化し、一般社員も意思決定を行う<br />- データを見る文化の醸造<br />- BI製品の利用           |
| 3  | 分析自動化       | データの収集から可視化までがシステム化されている<br />- ジョブコントローラー（流れの制御）が必要<br />- エンジニアリング力が不可欠 |
| 4  | データアプリケーション | 分析結果を利用したアプリケーションが運用されている<br />例: カスタマーの行動に応じた広告を出す                       |


## ビッグデータの収集

#### 収集方法

- ストリームデータ収集 ... データが生成されたら即時に収集する
- バッチデータ収集 ... 定期的にデータを収集する

| 観点          | ストリーム | バッチ   |
|:------------|:------|:------|
| 処理タイミング     | 随時    | 定期的   |
| データ鮮度       | ◯ 新しい | ✗ 古い  |
| 漏れのない収集     | ✗ 難しい | ◯ 可能  |
| 構築・運用の難易度   | ✗ 難しい | ◯ 易しい |
| 更新されるデータの収集 | ✗ 難しい | ◯ 可能  |
| 処理の負荷       | ◯ 均等  | ✗ 偏る  |

#### データ構造変更対応
ビジネスの変化で**データ構造・量が変化**するため、データ収集は分析システムの中でもっとも**運用が大変**。
決まったデータ構造にしか対応していないと、構造が変わったときに処理そのものが失敗してしまう。

##### 非同期方式と同期方式
企業内のデータ分析の優先度に応じて決まる。

![thumbnail](/assets/2024-05-18-big-data-bunnseki-no-system-to-kaihatu-ga-shikkari-wakaru-kyoukasyo/data-structure-modification-process.png)

### バッチ収集 対象ファイル

#### ファイルフォーマットの種類

##### csv
zipやgzipに圧縮して扱う。
データ型を定義できない。

##### json
階層型のデータを扱う場合に適している。
データ型を定義できない。

##### avro
avroはバイナリデータファイルで、独自のバイナリフォーマットでデータ量を小さくし、高速に処理できる。  
avscはavroのデータ構造定義ファイルで、階層型のデータも扱える。

#### ファイル収集のトリガー
事業システムで**トリガファイル**（ファイルの配置完了を示す）を作成する。トリガファイルがあれば収集する。

### バッチ収集 対象DB

#### SQLによる収集
SELECT文のカーソルを発行し、**少しずつフィッチ**して収集する。
データはローカルにファイルとして保存し、そのファイルをデータレイクに格納する。

##### 加工しつつ収集
SQLで匿名化加工などを行いつつ収集できる。

##### 並列に収集
収集対象テーブルを何かしらのキーで分割し、複数の収集ワーカーで同時に収集できる。

##### データベース負荷に注意
SQLによる収集は、事業システムのデータベースに最も負荷をかける。以下の点に注意する。

- データベースのキャッシュ洗い流し（アクセスの少ない時間帯に収集する）
- コネクション数溢れ
- 長時間トランザクション（一般的に障害扱いされてしまう）

#### データ出力による収集
データベースの**テーブルを出力**し、それをファイルとして収集する。
データベースの負荷が低いことがメリット。
ただし、整合性を保ったダンプかどうかに注意。

#### 更新ログ同期による収集
更新ログを取得して元のデータベースの複製を作る。一般的に「**準同期レプリケーション**」という。
環境構築が難しく運用も大変なため、事業データの負荷低減を最優先する場合のみ検討する。

### バッチ収集 対象システム

#### APIによる収集
データ構造が変わっても収集処理が失敗しないように、jsonをそのままデータレイクに格納することが重要。

#### スクレイピングによる収集
Webサイトの担当者と連絡が取れない場合、User-Agentに自身の連絡先を記載する。

### バッチ収集 ツール
バッチデータ収集を行うツールは、ETL（Extract Transform Load）と呼ばれる。

##### 製品ETL Embulk
コネクタがオープンソースのプラグインで、誰でも開発できる。
豊富なコネクタで、ほとんどのデータソースと接続できる。

##### 自作ETL
既存のETL製品は複雑すぎるため、半数以上は自作している。

### ストリーム収集
生成されるデータを受け止めて一時的に保持しておくために**分散キュー**を用いる。
分散キューは**難しい特性**が多く、運用が想像以上に難しい。

#### ストリーム収集 ツール

##### オープンソース
- Apache Kafka ... ビッグデータのストリームデータ収集のために作られたミドルウェア

##### マネージドサービス
- AWS Kinesis Data Streams ... 分散キューのマネージドサービス
- AWS Simple Queue Service ... 小さなデータ（システム間の命令）を伝達するためのサービス

##### 自作コンシューマー
分散キューのデータをデータレイクに入れるだけであれば、自前のプログラム（無限ループで分散キューのデータを処理する）でもよい。
AWS LambdaやGCP Cloud Functionsなどを利用すれば、分散キューにメッセージが入ったことをトリガにでき、常駐プログラム化が不要になる。

### データレイク
収集した生データをファイル（構造化データ: csv, 非構造化データ: 画像, テキスト, 音声）としてすべて溜めておく。
どんな形式のファイルも格納でき、データ量に応じてスケールアウトできる**分散ストレージ**が最適。


## ビッグデータの蓄積

### 一次加工
データレイクのデータを加工し、データウェアハウスに格納する。

| 処理          | 補足                                 |
|:------------|:-----------------------------------|
| バリデーション     | データ構造・型が想定通りか                      |
| 非構造化データの構造化 | 機械学習等を用いる                          |
| クレンジング      | 欠損値埋め、異常値削除、制御文字削除、フォーマット修正        |
| 名寄せ処理 | 「高」と「髙」を同じ文字として扱う                  |
| 結合処理 | トランザクションデータとマスターデータを結合して分析で使いやすくする |
| 機密情報の除去     | 個人情報のマスク処理                         |
| 表形式データへの変換  |                                    |

### データウェアハウス

#### アナリティックDB
データを一括ロードしたあと、**データ全体に集計をかけるような処理を得意**とする。
応答速度よりもスループットに重点を置く。

##### 列指向
列方向にデータを固めて保持する。特定列への集計は、データ全体のスキャンが不要なため、高速になる。

ある行の更新で、その行を含む全ての列指向データを書き換えなければいけないため、データの更新や削除は非常に低速にある。

### 列指向フォーマット

#### 列指向フォーマット
データを特定の列ごとに圧縮して保持し、抽出や集計が高速になるように作られたデータフォーマットのこと。

#### 符号化によるデータ圧縮
「列方向には同じようなデータが並ぶ」という特性を利用して、データを符号化し圧縮する。

具体的には、為替レートの例では、平均値の値とその差分だけを格納するようにする。

| 観点       | オペレーショナルDB | アナリティックDB  |
|:---------|:-----------|:-----------|
| 得意な処理    | データの細かい操作  | データの抽出・集計  |
| データの持ち方  | 行指向        | 列指向        |
| 重要視する性能  | 応答速度       | スループット     |
| 更新・削除    | ◯ できる      | △ できないor遅い |
| トランザクション | ◯ RDBはできる  | ✗ できない     |
| データの集計   | ✗ 遅い       | ◯ 速い       |
| データのロード  | ✗ 遅い       | ◯ 速い       |

##### アナリティックDB製品
- SQL on Hadoop
- DWH製品
  - オンプレミス: Teradata
  - クラウド: AWS Redshift, GCP BigQuery, Snowflake

### SQL on Hadoop

### DWH製品

#### BigQuery
GCPで利用できるデータウェアハウスサービス。
Redshiftはあらかじめクラスターを確保する必要があるため、常に固定のコストを支払う必要があるが、
BigQueryはクエリごとの課金であるため、この点が大きく異なる。

データはオブジェクトストレージであるGCSからBigQueryの中にロードして利用することが一般的。
大企業においては、部門ごとにクエリの費用は負担するがデータは共有したいケースが多いため、そのようなユースケースにマッチする。

#### Snowflake
BigQueryと似たような機能をAWSやAzureで利用したい場合にはSnowflakeが選択肢になる。

#### オペレーショナルDB
少量のデータに対してランダムにデータ操作することが得意。
処理の応答速度を重視し、一回のクエリであれば数ミリ秒から数十ミリ秒で処理。

##### 行指向
行に対するアクセスが高速に動作するように作られている。

##### オペレーショナルDB製品

- リレーショナルデータベース
  - オンプレミス: MySQL, SQL Server
  - クラウド: AWS Aurora
- NoSQLデータベース
  - オンプレミス: MongoDB
  - クラウド: AWS DynamoDB




アドホック分析のために、SQLインターフェイスや作業用データスペースを準備する。
データ利用者にリソースを使いつくされないようにリソース制限をかける。

データウェアハウスはアナリティックデータベースで構築する。

データウェアハウスはデータレイクよりも容量あたりの費用が高価であるため、
データウェアハウスにすべてのデータを入れることは現実的ではない。

### データレイクとデータウェアハウス

#### データウェアハウスの実現方法
データベース製品は2種類ある。

- オペレーショナルDB
  - データの操作を得意とする
- アナリティックDB
  - データの分析を得意とする

### アナリティックDB




## ビッグデータの活用

### データ活用
データ可視化やデータアプリケーションから利用する場合は、それら用に特別に加工したデータマートを準備する。

#### データマート
データウェアハウスのデータを加工して、目的ごとに応じたデータに変換する。

#### データ可視化
データ可視化の責任範囲は、「意思決定が行われる」まで。
定期的に使われていないレポートを改善・廃棄する。

#### データアプリケーション
データを企業利益に結びつけるための「その他すべて」。
データアプリケーションも分析システムの一部として常に管理する。
最終的に利益に結び付く部分まで責任を持つことが重要。

### データマート
計算リソースの最適利用と汎用的な集計の統一がデータマートを作る目的。

#### データマートの作り方

1. SQLを利用する
  - ただしSQLで完結する場合に限る
1. SQLに加えてUDF（ユーザー定義関数）を合わせて利用する
  - SQLには用意されていない関数を実現したい場合に用いる
  - BigQueryであればJSで書くことができる
1. 外部で計算する
  - UDFで利用できない外部ライブラリを利用する場合に用いる（GPUを利用した機械学習など）
  - 最近では、BigQuery MLのようにSQLの文法のみで機械学習が実現できたりする

### アドホック分析

#### 皆に認知され簡単にデータを分析できる環境
すばらしい成果を出す優秀なデータサイエンティストが1人いることよりも、
データを見て意思決定できる社員が100人いるほうが、企業にとっては有益。

#### 誰でも使えるユーザインターフェース
誰でも簡単にデータを分析できるためには、ユーザインターフェースやメタデータの開示が重要。
敷居の低いユーザインターフェースでなければ普及は見込めない。

**図**

#### メタデータの開示
データの意味を簡単に知ることのできるドキュメントやポータルが必要。

### アドホック分析環境の構築

#### アドホック分析環境のデータ利用者サポート
必要なデータ利用者サポート

1. 一般的なシステムユーザ管理プロセス
1. 問い合わせ対応窓口の準備
1. 障害発生時の通知手段


## メタデータ管理

#### メタデータ管理
データの付加情報。

- データ構造
  - 名前や型
- データ鮮度
  - いつ時点のデータか
- データリネージ
  - どこから来てどこに行くのか
- データ辞書
  - ビジネス上の意味を説明

### 全体像と静的メタデータ

#### インターネット事業会社でよく使うメタデータ

**メタデータ一覧**

#### 静的メタデータ

##### データ構造
データ構造はデータ利用者が頻繁に調べる情報であるため、
データ利用者がブラウザで簡単に検索できるようにwebサイトを作り公開します。
このようなサイトを「データカタログ」と呼ぶ。

##### データ辞書
ビジネス文脈上でのデータの意味。
データ辞書はデータカタログの１コンポーネントとして扱い、データ構造と一緒にデータ利用者に公開する。
データ利用者がデータ辞書の内容を簡単に編集できるように、編集リクエストやレビュー機能を備える。

##### データオーナ
データの意味がわからない場合には、最終的にデータオーナに聞きに行く必要がある。

##### データリネージ
データがどこから来てどこに行くのかを表す情報。
障害が発生したときの影響範囲の調査と、データ生成元の調査で使う。

### 動的メタデータとメタデータ管理実現方法

#### 動的メタデータ

##### データ統計値
それまで毎日レコード数が単調増加していたテーブルが、ある日を境にレコード数が増えなくなった場合に、
データ収集がうまく動作していないことを疑うことができる。

#### メタデータ管理の実現方法
多くの場合、製品を使うのではなく自前でメタデータ管理アプリケーションを作っている。

今後は製品が拡充されてくると考えられる。
メタデータ管理製品として紹介したいのは、GCP Data Catalog。
メタデータの管理サービス。

### データマネジメント知識体系DMBOK
メタデータ管理はデータマネジメントの一貫。
興味がある人はDMKBOK(Data Management Body of Knowledge)を読んでみるとよい。

### データ構造管理
構造管理の目的
1. データの調査効率化
1. データ構造変更の検知

#### データカタログの責任者
データカタログの責任者を企業に置く。

**図**

#### データ構造変更の検知
データ構造変更については事前に内容を把握し、事業システムと足並みを揃えて計画的に対応していくことが必要。

#### データ構造変更の検知の実現方法
事業システムのデータ定義ドキュメントの場所を教えてもらい、そのドキュメントを解析してデータ構造を抽出する。

#### データカタログとデータ構造変更管理システム
２つのシステムを同じwebサイトとして同居させても良いが、要件の異なる2つのシステムであることを忘れない。

### データリネージ管理

#### データリネージを管理しないと何が起きるのか
問題・障害発生時の影響調査に苦労する。

#### データリネージ管理の実現方法
実際の現場では自前でデータリネージを管理するシステムを用意する。
データを生成する処理全てに対して、どのデータを入力とし、どのデータを出力するのか、データリネージ管理システムに登録する。

### データ鮮度管理

#### データ鮮度の定義

- 収集するデータが更新されない場合（時系列データ等）
  - タイムスタンプを採用
- 収集するデータが更新される場合
  - データの中に更新日を格納してもらう

#### データ鮮度の記録

- 埋め込み方式  
  データに列を追加してその列にデータ鮮度を記録
- 外部管理方式  
  別途データ鮮度管理システムを作る


## 3章 分散処理の基礎

### ボトルネック解析

#### 性能問題とボトルネック
ビッグデータ分析では、問題のほとんどは性能問題。
「ボトルネック」を解析して、それを解消する。
システムのボトルネックとは、処理時間の中で「その部分が早くなれば全体の処理時間が短くなる部分」のこと。

#### ディスクボトルネック
ビッグデータ分析では、ディスクのボトルネックがもっとも多い。

#### プロセッサボトルネック
プロセッサの使用率監視をするときは、コアごとに行うことが鉄則。

### ボトルネック以外の性能問題考慮点

#### メモリの枯渇
メモリのスワップアウトが発生していないかを確認することが重要。

#### 移り変わるボトルネック
ボトルネックは移り変わっていき、ボトルネックが無くなるということはない。
ボトルネックは解消を続けて、業務要件に見合う処理速度になったときに、性能問題を解消できたことになる。

#### ボトルネックがないのに遅い
原因として、処理が非効率であることが考えられる。

### 分散ストレージ

#### 複数のコンピューターにディスクを分散
8個のディスクの付いたコンピューターを10台用意すれば、80個のディスクから同時に読み出すことができる。

#### 分散ストレージのアーキテクチャ

- レプリケーション
  - １つのデータの複製を複数のコンピューターで保持し、可用性を高める
- リードレプリカ
  - データの複製に対して読み取りを許可して読み取りのスループットを上げる方式

**図**

#### 分散ストレージとオブジェクトストレージ
クラウドのオブジェクトストレージも分散ストレージの一種。
扱うデータの単位はファイルであり、データを分散して格納しアプリケーションには透過的にデータにアクセスできるエンドポイントを提供する。

#### 結果整合性
「分散ストレージに加えた変更は、すぐに見えるとは限らない」
分散化されたストレージ間での状態の共有にラグが存在する。

### 分散計算

#### 分散計算
アプリケーションはコーディネーターに計算を提出し、コーディネーターが複数の計算ノードに計算の指示をして、結果をまとめてアプリケーションに返す。

**図**

#### SQLの分散計算
記述が難しすぎるため、実際の現場ではMapReduceはほとんど使われない。
SQLの分散計算でもっとも有名なのはHadoopプロジェクトのHive。
HiveはSQLをMapReduceの関数に書き換えて分散計算する。

#### 計算の分散方法を考える癖
ビッグデータ分析において重要なのは、やろうとしている計算が分散できるのかを常に考えること。

### 分散システムのネットワーク

#### オンプレミス環境におけるネットワークボトルネックの解消
ネットワークの全体像がつかめればどこがボトルネックであるかわかってくる。

#### オンプレミスからクラウドへのネットワーク通信
オンプレミスとクラウドを結ぶ通信は物理的に離れていることが多く、
大きな帯域幅を維持することも難しいため、ネットワークのボトルネックになりがち。

### リソースマネージャ

#### リソースマネージャ
複数のコンピューターをまとめて「クラスター」として扱い、クラスター全体のリソース（主にCPUとメモリ）を管理して、分散処理に割り当てる役割を担う。

### 分散処理の作り方

#### Hadoopを利用した分散処理
HadoopプロジェクトはApacheソフトウェア財団のプロジェクトの１つであり、分散処理をするためのさまざまなソフトウェアの総称。

Hadoopの欠点は、「ソフトウェアそのものが重厚長大で運用が大変である」ということ。
Hadoopを数十台程度の規模で利用してしまうと、Hadoopの分散処理により得られるハーでウェアの節約コストよりも、Hadoopそのものを運用する人件費の方が高価になってしまう。
数十台程度の規模であれば、クラウドをうまく利用すれば作れるため、Hadoopはあまり使われなくなってきている。

#### 自前で作る分散処理
ファイルを処理するワーカーと、それを並列実行させるためのキューとマネージャがあれば実現できる。
自作では、簡単に作れるが運用がそれなりの負荷になる。さまざまな異常ケースに対応しなければいけないため。

#### 分散処理できるクラウドサービス
Hadoopの利用も自前の分散処理もそれなりに手間。クラウドを利用するともっと楽。

- データウェアハウスサービス
  - AWS Redshift
  - GCP BigQuery
- マネージドETLサービス（データの抽出・変換・挿入）
  - AWS Glue
  - GCP Data Fusion

## 4章 機械学習の基礎

### 機械学習

#### 機械学習の種類

- 教師あり機械学習 回帰
  - 過去のデータをもとに未来のデータの数値を予測
- 教師あり機械学習 分類
  - 過去のデータをもとにデータの分類を予測
- 教師なし機械学習
  - 大量のデータから規則性や類似性を導き出して、データを特徴づけたり分類したりする
- 強化学習
  - 各状況で機械がとった行動に対して「報酬」という形で間接的にフィードバックを与える

#### 教師あり機械学習 回帰
1次関数を用いた回帰を「重回帰分析」といい、ビジネスの現場でもよく使われる

### データの準備と前処理

#### 前処理・特徴量抽出
カスタマーの行動特徴をうまく表現するデータに変換することが必要。
データの特徴を表す数値を「特徴量」という。

#### 訓練データ・検証データ・テストデータ
推定されたモデルは検証データをうまく予測するように作られているため、テストデータを検証データと別に用意する。

機械学習では準備が非常に大変で、「データサイエンティストの仕事の8割が準備」と言われることもある。

### モデル推定とシステム化

#### モデル推定
訓練データと検証データを用いてモデルを推定し、テストデータで評価した結果を踏まえて、
モデルや特徴量の改善を繰り返し実施することにより、モデルの精度を高めていく。
このプロセスを「学習」という。

#### ハイパーパラメータチューニング
モデルそのもののパラメータ以外の要因のことをハイパーパラメータという。学習する回数、アルゴリズム、学習を止めるしきい値など。
さまざまなハイパーパラメータを試すことを、「ハイパーパラメータチューニング」という。

### 本番リリースとエンハンス

#### 本番リリースとABテスト
ABテストは、実際に今動いているモデルの予測結果の中に、新しく作ったモデルの予測結果を少しだけ混ぜ込んで、
実際のカスタマーの挙動に悪影響を及ぼさないかを確認するテスト。

#### エンハンス
モデルの精度が劣化してきた場合に、モデルの精度がもとに戻るようにエンハンスする。
初期構築したデータサイエンティストにエンハンスの方法を引き継いでもらうことを徹底する。

### ディープラーニング

#### ディープニューラルネットワーク
ディープニューラルネットワークであっても、一次関数であっても、機械学習の計算全体から見ると同じ役割。
しかし、一次関数とディープニューラルネットワークでは計算の複雑さが全く違う。

**表**

### 機械学習ツール

#### Python
- NumPy
  - 数値計算ライブラリ
- Pandas
  - データの前処理や特徴量エンジニアリングに最適

#### Jupyter Notebook
予測精度を表すグラフをプログラムと共に成果物として管理する。
